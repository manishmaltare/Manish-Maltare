# -*- coding: utf-8 -*-
"""deployment 3 solar panelsipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sIkOnMYaPwlnb0L-ZKJTYJPd3JUl04NL
"""

# app.py
# Single-file Streamlit app that trains once (if needed) and serves predictions.
# Requirements: scikit-learn, pandas, numpy, joblib, streamlit

import os
import joblib
import pickle
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingRegressor
import streamlit as st

# -----------------------
# Config / artifact paths
# -----------------------
DATA_CSV = "solarpowergeneration.csv"
SCALER_PATH = "scaler.joblib"
MODEL_PATH = "gbr_model.joblib"
TRAIN_MIN_PATH = "train_min.joblib"
TRAIN_MAX_PATH = "train_max.joblib"
FEATURE_NAMES_PATH = "feature_names.joblib"

# -----------------------
# Helper: train & export
# -----------------------
def train_and_export():
    st.info("Training model (this runs once) â€” please wait...")
    df = pd.read_csv(DATA_CSV)

    # Fill NaNs same as your original pipeline
    if "average-wind-speed-(period)" in df.columns:
        df['average-wind-speed-(period)'] = df['average-wind-speed-(period)'].fillna(
            df['average-wind-speed-(period)'].mean()
        )

    # Prepare features & target
    if 'power-generated' not in df.columns:
        st.error("CSV must contain 'power-generated' column.")
        st.stop()

    features = df.drop(['power-generated'], axis=1)
    target = df['power-generated']

    # Fit scaler
    scaler = StandardScaler()
    scaler.fit(features)  # fits using training distribution (whole file)

    # Save min/max and feature names for OOD checks and UI ranges
    train_min = features.min().to_numpy()
    train_max = features.max().to_numpy()
    feature_names = features.columns.tolist()

    # Use the same indexing split you used originally
    X_all = scaler.transform(features)
    X_train = X_all[0:2336]
    y_train = target.iloc[0:2336]

    # Train model
    model = GradientBoostingRegressor(
        learning_rate=0.1, max_depth=3, n_estimators=100, random_state=42
    )
    model.fit(X_train, y_train)

    # Export artifacts
    joblib.dump(scaler, SCALER_PATH)
    joblib.dump(model, MODEL_PATH)
    joblib.dump(train_min, TRAIN_MIN_PATH)
    joblib.dump(train_max, TRAIN_MAX_PATH)
    joblib.dump(feature_names, FEATURE_NAMES_PATH)

    st.success("Training complete. Artifacts saved.")
    return scaler, model, train_min, train_max, feature_names

# -----------------------
# Helper: load artifacts
# -----------------------
@st.cache_resource
def load_or_train():
    # If artifacts exist, load them; otherwise train and export
    all_exist = all(os.path.exists(p) for p in [SCALER_PATH, MODEL_PATH, TRAIN_MIN_PATH, TRAIN_MAX_PATH, FEATURE_NAMES_PATH])
    if all_exist:
        try:
            scaler = joblib.load(SCALER_PATH)
            model = joblib.load(MODEL_PATH)
            train_min = joblib.load(TRAIN_MIN_PATH)
            train_max = joblib.load(TRAIN_MAX_PATH)
            feature_names = joblib.load(FEATURE_NAMES_PATH)
            return scaler, model, train_min, train_max, feature_names
        except Exception as e:
            st.warning(f"Error loading artifacts ({e}). Retraining...")
            return train_and_export()
    else:
        # If CSV missing, we cannot train
        if not os.path.exists(DATA_CSV):
            st.error(f"{DATA_CSV} not found. Place CSV in the app folder or pre-create artifacts.")
            st.stop()
        return train_and_export()

# -----------------------
# App UI and logic
# -----------------------
st.set_page_config(page_title="Solar Panel Regression App", page_icon="âš¡", layout="wide")
st.markdown("""
    <style>
    body { background-color: #0f1720; color: #e6eef2; }
    .input-card { background: #0b1220; padding: 20px; border-radius: 12px; box-shadow: 0 6px 18px rgba(0,0,0,0.6); }
    .prediction-box { background: #0ea5a4; color: #0b1220; padding: 18px; border-radius: 12px; font-weight:700; text-align:center; }
    .small-muted { font-size:12px; color:#9aa7b2; }
    </style>
""", unsafe_allow_html=True)

st.markdown("<h1 style='text-align:center;'>âš¡ Solar Panel Regression App</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;' class='small-muted'>Trains automatically if needed â€” otherwise loads saved model.</p>", unsafe_allow_html=True)

# Load artifacts (train if required)
scaler, model, train_min, train_max, feature_names = load_or_train()

# Convert min/max to Series for convenience
train_min_s = pd.Series(train_min, index=feature_names)
train_max_s = pd.Series(train_max, index=feature_names)

# Input card
st.markdown("<div class='input-card'>", unsafe_allow_html=True)
st.markdown("### ðŸŒ¤ Enter Environmental Parameters")
st.write("Provide environment values. Values shown are based on training data ranges. Results can be unreliable for inputs outside those ranges.")

cols = st.columns(3)
user_input = {}
for i, feat in enumerate(feature_names):
    col = cols[i % 3]
    min_v = float(train_min_s[feat])
    max_v = float(train_max_s[feat])
    # If min==max (no variance), create a small display range
    diff = max_v - min_v
    pad = diff * 0.05 if diff != 0 else max(1.0, abs(min_v) * 0.05)
    display_min = min_v - pad
    display_max = max_v + pad
    default_v = float((min_v + max_v) / 2.0) if diff != 0 else float(min_v)

    with col:
        # Use slider when range is reasonable
        try:
            step = (display_max - display_min) / 100.0
            if step <= 0:
                step = 1.0
            user_input[feat] = st.slider(
                label=feat.replace("-", " ").title(),
                min_value=float(display_min),
                max_value=float(display_max),
                value=default_v,
                step=step
            )
        except Exception:
            user_input[feat] = st.number_input(
                label=feat.replace("-", " ").title(),
                value=default_v
            )

st.markdown("</div>", unsafe_allow_html=True)

# Convert input to DataFrame with same column order as training
user_df = pd.DataFrame([user_input])[feature_names]

# Utility functions
def check_ood(X_raw, train_min_arr, train_max_arr):
    return (X_raw < train_min_arr) | (X_raw > train_max_arr)

def domain_no_sun_rule(inputs):
    # Domain heuristics (tweak these to your knowledge)
    if "sky-cover" in inputs and float(inputs["sky-cover"]) >= 0.99:
        return True
    if "visibility" in inputs and float(inputs["visibility"]) <= 0.01:
        return True
    return False

# Prediction
if st.button("ðŸ” Predict Power Generation", use_container_width=True):
    arr = user_df.to_numpy(dtype=float).reshape(-1)
    # 1) all-zero check -> now returns 0 kW instead of error
    if np.allclose(arr, 0.0):
        st.info("All inputs are zero â€” predicted power = 0 kW")
        st.markdown("<div class='prediction-box'>ðŸŒž Predicted Power: <br>0.00 kW</div>", unsafe_allow_html=True)
        # Stop further processing for this button click
        st.stop()
    else:
        # 2) domain rule for no sunlight
        if domain_no_sun_rule(user_input):
            st.info("Environmental conditions indicate no sunlight â€” predicted power = 0 kW")
            st.markdown("<div class='prediction-box'>ðŸŒž Predicted Power: <br>0.00 kW</div>", unsafe_allow_html=True)
        else:
            # 3) OOD check
            ood_mask = check_ood(arr, train_min, train_max)
            if ood_mask.any():
                st.warning("One or more inputs are outside the training data range â€” results may be unreliable.")
                ood_indices = np.where(ood_mask)[0]
                ood_feats = [feature_names[i] for i in ood_indices]
                st.write("Out-of-range features:", ood_feats)

            # 4) Scale and predict
            try:
                X_scaled = scaler.transform(user_df.to_numpy().reshape(1, -1))
            except Exception as e:
                st.error(f"Error while scaling inputs: {e}")
            else:
                if np.isnan(X_scaled).any() or np.isinf(X_scaled).any():
                    st.error("Invalid input values after scaling (NaN or Inf).")
                else:
                    pred = model.predict(X_scaled)[0]
                    st.markdown(f"<div class='prediction-box'>ðŸŒž Predicted Power: <br>{pred:.2f} kW</div>", unsafe_allow_html=True)

# Optional: show training ranges for debugging (collapsed)
with st.expander("Show training ranges and feature names (debug)"):
    df_ranges = pd.DataFrame({
        "feature": feature_names,
        "train_min": train_min,
        "train_max": train_max
    })
    st.dataframe(df_ranges)

# Footer
st.markdown("<p style='text-align:center; font-size:12px; color:#9aa7b2;'>If you update the CSV or want to retrain, delete the model/scaler files and reload the app.</p>", unsafe_allow_html=True)