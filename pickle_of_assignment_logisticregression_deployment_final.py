# -*- coding: utf-8 -*-
"""Pickle of ASSIGNMENT - LogisticRegression - Deployment - Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YSv7MZYOcWAHmiNHz4RF5JwWfbbNkNb6
"""

import pandas as pd # LOAD DATASET
import joblib

features = pd.read_csv('Titanic_train.csv')

target = pd.read_csv('Titanic_test.csv')

# FEATURE EXTRACTION - i did perform it before EDA- 1 as the feature & target variable are given
# separately.

features.shape

target.shape

features.isnull().sum()

features

features.shape

features.info()

features.describe()

# DATA PREPROCESSING : - "Imputation"
# Imputation i am using here to fill the blank rows, keeping rows empty can lead to
# model not run.
# I am using imputation here by filling the 'age' column with mean value of overall rows.

features['Age']=features['Age'].fillna(features['Age'].mean())

features.isnull().sum()

features['Embarked'].value_counts()

# i am using imputation by applying most frequent rows into the blank ones in
# Embarked, as its having only 2-rows empty.

features['Embarked']=features['Embarked'].fillna(features['Embarked'].mode()[0])

features.isnull().sum()

features['Embarked'].value_counts()

# i am using imputation here, by first separating first letter of Cabin,
# beacause, it is deck no. which i feel is the only useful for process.
# After that i did put a random string 'U' in the null rows.

features['Cabin']=features['Cabin'].str[0]

features['Cabin']

features['Cabin']=features['Cabin'].fillna('U')

features['Cabin'].value_counts()

features.isnull().sum()

features.columns

features.nunique()

# I drop the columns PassengerID & Name.
# Main reason : - having data value in all rows unique, Regression will not work.
# PassengerID is just serial no. as per the registration. and in +1 incerasing order.
# Name - i believe would not matter, as there are string data, which is not eay to convert
# into continuous no. or binary

features=features.drop(['PassengerId','Name'],axis=1)

features.head()

# DATA PREPROCESSING : - "Encode categorical data"

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

features.head()

features.value_counts()

features['Sex'].value_counts()

features['Embarked']=le.fit_transform(features['Embarked'])

features['Embarked'].value_counts()

features['Sex']=le.fit_transform(features['Sex'])

features['Sex'].value_counts()

features.head()

features.nunique()

# removing ticket as its having 76% on unique values as string & integers.
features=features.drop(['Ticket'],axis=1)

features['Cabin']=le.fit_transform(features['Cabin'])

features['Cabin'].value_counts()

features.head()

target.head()

target.shape

target.nunique()

target.columns

target=target.drop(['PassengerId','Name','Ticket'],axis=1)

target.head()

target.isnull().sum()

# Repeating the same steps of Data preprocessing for 'target' varable to prepare the dataset for prediction.

target['Age']=target['Age'].fillna(target['Age'].mean())

target['Age'].value_counts()

target.isnull().sum()

target['Cabin']=target['Cabin'].str[0]

target.head()

target['Cabin']=target['Cabin'].fillna('U')

target['Cabin'].value_counts()

target.head()

# merging 'features' & 'target' variables to perform EDA.
# EDA-1

data_merged=pd.concat([features,target],ignore_index=True)
data_merged.head()

data_merged.columns

data_merged.shape

data_merged.size

data_merged.info()

data_merged.describe()
# Age , the average is 29.88 years. Max is 88 years old.
# Fare, Max. fare price is 512, avg is 33.29 units.
# Pclass, mean is 2.29 indicates that most people are of middle income group (2nd class).
# 75% people are from calss 3rd, which means majority people travelling are of class 3rd.

target['Sex']=le.fit_transform(target['Sex'])

target['Embarked']=le.fit_transform(target['Embarked'])

target['Cabin']=le.fit_transform(target['Cabin'])

target.head()

x = features.drop(['Survived'],axis=1)
x.head()

x.columns

y= features['Survived']
y.head()

# EDA-2 (MODEL BUILDING)
from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,train_size=0.8)

x_train.shape,x_test.shape,y_train.shape,y_test.shape

column_names=x_train.columns
column_names

x_train.head()

x_train.isnull().sum()

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

x_train=sc.fit_transform(x_train)

x_test=sc.fit_transform(x_test)

from sklearn.linear_model import LogisticRegression

model=LogisticRegression()

model1 = model.fit(x_train,y_train)

import pickle

with open("logistic_regression_model.pkl", "wb") as file:
  pickle.dump(model1, file)

import numpy as np

import pandas as pd

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py

import streamlit as st
import pickle
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Load the trained model
with open("logistic_regression_model.pkl", "rb") as file:
    model = pickle.load(file)

# Title of the Streamlit app
st.title("Titanic Survival Prediction")

# Description
st.write("Enter passenger details to predict survival probability on the Titanic.")

# Input fields for features
pclass = st.selectbox("Passenger Class (Pclass)", [1, 2, 3])
sex = st.selectbox("Sex", ["male", "female"])
age = st.number_input("Age", min_value=0, max_value=100, value=30)
sibsp = st.number_input("Number of Siblings/Spouses Aboard (SibSp)", min_value=0, max_value=10, value=0)
parch = st.number_input("Number of Parents/Children Aboard (Parch)", min_value=0, max_value=10, value=0)
fare = st.number_input("Fare", min_value=0, max_value=600, value=30)
cabin = st.selectbox("Cabin Deck", ["A", "B", "C", "D", "E", "F", "G", "T", "U"])
embarked = st.selectbox("Port of Embarkation", ["C", "Q", "S"])

# Encode categorical variables
le_sex = LabelEncoder()
le_sex.fit(["male", "female"])
sex_encoded = le_sex.transform([sex])[0]

le_embarked = LabelEncoder()
le_embarked.fit(["C", "Q", "S"])
embarked_encoded = le_embarked.transform([embarked])[0]

le_cabin = LabelEncoder()
le_cabin.fit(["A", "B", "C", "D", "E", "F", "G", "T", "U"])
cabin_encoded = le_cabin.transform([cabin])[0]

# Create a DataFrame for the input
input_data = pd.DataFrame({
    'Pclass': [pclass],
    'Sex': [sex_encoded],
    'Age': [age],
    'SibSp': [sibsp],
    'Parch': [parch],
    'Fare': [fare],
    'Cabin': [cabin_encoded],
    'Embarked': [embarked_encoded]
})

input_data_scaled = StandardScaler()
input_data_scaled.fit_transform(input_data)

# Predict button
if st.button("Predict"):
    prediction = model.predict(input_data_scaled)
    probability = model.predict_proba(input_data_scaled)[0][1]  # Probability of survival

    # Display result
    if prediction[0] == 1:
        st.success(f"The passenger is likely to **survive** with a probability of {probability:.2f}.")
    else:
        st.error(f"The passenger is likely to **not survive** with a probability of {1 - probability:.2f}.")
