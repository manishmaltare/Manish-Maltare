# -*- coding: utf-8 -*-
"""ASSIGNMENT - LogisticRegression - Deployment - Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gmPcc_b1ChktZVuTt6Vm1lihRKaTwxpL
"""

import pandas as pd # LOAD DATASET
import joblib
features = pd.read_csv('Titanic_train.csv')
features = features.drop('Ticket', axis=1)
features = features.drop('Name', axis=1)
features = features.drop('Name', axis=1)

target = pd.read_csv('Titanic_test.csv')

# FEATURE EXTRACTION - i did perform it before EDA- 1 as the feature & target variable are given
# separately.

features.shape

target.shape

features.isnull().sum()

# DATA PREPROCESSING : - "Imputation"
# Imputation i am using here to fill the blank rows, keeping rows empty can lead to
# model not run.
# I am using imputation here by filling the 'age' column with mean value of overall rows.

features['Age']=features['Age'].fillna(features['Age'].mean())

features.isnull().sum()

# i am using imputation by applying most frequent rows into the blank ones in
# Embarked, as its having only 2-rows empty.

features['Embarked']=features['Embarked'].fillna(features['Embarked'].mode()[0])

features.isnull().sum()

# i am using imputation here, by first separating first letter of Cabin,
# beacause, it is deck no. which i feel is the only useful for process.
# After that i did put a random string 'U' in the null rows.

features['Cabin']=features['Cabin'].str[0]

features['Cabin']

features['Cabin']=features['Cabin'].fillna('U')

features['Cabin']

features.isnull().sum()

features.columns

features.nunique()

# I drop the columns PassengerID & Name.
# Main reason : - having data value in all rows unique, Regression will not work.
# PassengerID is just serial no. as per the registration. and in +1 incerasing order.
# Name - i believe would not matter, as there are string data, which is not eay to convert
# into continuous no. or binary

features=features.drop(['PassengerId','Name'],axis=1)

features.head()

# DATA PREPROCESSING : - "Encode categorical data"

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

features['Sex']=le.fit_transform(features['Sex'])

features.head()

features['Embarked']=le.fit_transform(features['Embarked'])

features.head()

features.nunique()

# removing ticket as its having 76% on unique values as string & integers.

features['Cabin']=le.fit_transform(features['Cabin'])

features.head()

target.head()

target.shape

target.nunique()

target.columns

target=target.drop(['PassengerId','Name','Ticket'],axis=1)

target.head()

target.isnull().sum()

# Repeating the same steps of Data preprocessing for 'target' varable to prepare the dataset for prediction.

target['Age']=target['Age'].fillna(target['Age'].mean())

target.isnull().sum()

target['Cabin']=target['Cabin'].str[0]

target.head()

target['Cabin']=target['Cabin'].fillna('U')

target.head()

# merging 'features' & 'target' variables to perform EDA.
# EDA-1

data_merged=pd.concat([features,target],ignore_index=True)
data_merged.head()

data_merged.columns

data_merged.shape

data_merged.size

target['Sex']=le.fit_transform(target['Sex'])

target['Embarked']=le.fit_transform(target['Embarked'])

target['Cabin']=le.fit_transform(target['Cabin'])

target.head()

x = features.drop(['Survived'],axis=1)
x.head()

x.columns

y= features['Survived']
y.head()

# EDA-2 (MODEL BUILDING)
from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,train_size=0.8)

x_train.shape,x_test.shape,y_train.shape,y_test.shape

column_names=x_train.columns
column_names

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

x_train=sc.fit_transform(x_train)

x_test=sc.fit_transform(x_test)

from sklearn.linear_model import LogisticRegression

model=LogisticRegression()

model.fit(x_train,y_train)

scaler1 = sc.fit_transform(x_train)

# 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked'
scaler = pd.DataFrame(scaler1, columns=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked'])

joblib.dump(model,'logistic_reg_model.pkl') # Creating a PKL file for deployment later

joblib.dump(scaler,'scaler.pkl')

y_pred=model.predict(x_train)

# MODEL EVALUATION
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_train,y_pred)
cm
# TP = 383 (correctly predicted survived)
# TN = 185 (correctly predicted not-survived)
# FP = 61 (incorrectly predicted survived)
# FN = 83 (incorrectly predicted not-survived)

from sklearn.metrics import classification_report

cr=classification_report(y_pred,y_train)

print(cr)

column_names

pd.DataFrame({'Column0': ['x1','x2','x3','x4','x5','x6','x7','x8'],'Column':column_names, 'Values': model.coef_.reshape(-1)})

# CHECKING TEST ACCURACY OF MODEL

model1=LogisticRegression()

model1=model1.fit(x_test,y_test)
model1

y_pred1=model1.predict(x_test)

y_pred1

cm1=confusion_matrix(y_pred1,y_test)
cm1
# TP = 92 (correctly predicted survived)
# TN = 58 (correctly predicted not-survived)
# FP = 16 (incorrectly predicted survived)
# FN = 13 (incorrectly predicted not-survived)

cr1=classification_report(y_pred1,y_test)

print(cr1) # Testing accuracy F1 - Score is 84%
# Testing model

target.head()

features.head()

target.isnull().sum()

target['Fare'].head()

target['Fare'].tail()

target['Fare'].iloc[152]

target.shape

target=target.drop([152])

target['Fare'].iloc[152]

target.shape

from sklearn.metrics import roc_curve, auc

# PREDICTION OF TARGET VARIABLES (using file "Titanic_test.csv" )
y_pred_new=model.predict(target)
y_pred_new

# Deployment :

model

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py

import streamlit as st
import pandas as pd
import numpy as np
import joblib


# ------------------- PAGE CONFIG -------------------
st.set_page_config(
    page_title="Titanic Survival Prediction App",
    layout="centered"
)

# ------------------- CACHING MODEL -------------------
@st.cache_resource
def load_model_and_scaler():
    try:
        return (
            joblib.load('logistic_reg_model.pkl'),
            joblib.load('scaler.pkl')
        )
    except FileNotFoundError as e:
        st.error(f"‚ö†Ô∏è Missing file: {e}. Ensure 'logistic_reg_model.pkl' and 'scaler.pkl' are present.")
        st.stop()

model, scaler = load_model_and_scaler()

# ------------------- MAPPINGS -------------------
# Ensure these match the LabelEncoder classes used during training
SEX_MAPPING = {'Female': 0, 'Male': 1}
EMBARKED_MAPPING = {'S': 2, 'C': 0, 'Q': 1}
CABIN_MAPPING = {'U': 8, 'C': 2, 'B': 1, 'D': 3, 'E': 4, 'A': 0, 'F': 5, 'G': 6, 'T': 7}

# ------------------- TITLE -------------------
st.title("üö¢ Titanic Survival Prediction App")
st.write("Fill in the passenger details below to get the survival prediction:")

# ------------------- INPUT LAYOUT -------------------
col1, col2 = st.columns(2)

with col1:
    pclass = st.selectbox('Pclass', [1, 2, 3],
                          format_func=lambda x: f"{x} ({'First' if x==1 else 'Second' if x==2 else 'Third'})")
    age = st.number_input('Age', 0, 100, 29)
    parch = st.number_input('Parch', 0, 10, 0, help="Number of Parents/Children Aboard")
    embarked = st.selectbox('Embarked', list(EMBARKED_MAPPING.keys()))

with col2:
    sex = st.selectbox('Sex', list(SEX_MAPPING.keys()))
    sibsp = st.number_input('SibSp', 0, 10, 0, help="Number of Siblings/Spouses Aboard")
    fare = st.number_input('Fare', 0.0, 600.0, 32.2)
    cabin = st.selectbox('Cabin', list(CABIN_MAPPING.keys()))

# ------------------- PREDICTION FUNCTION -------------------
@st.cache_data(show_spinner=False)
def predict_survival(features):
    """Predict survival with scaled input."""
    input_df = pd.DataFrame([features],
                            columns=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked'])
    input_scaled = scaler.transform(input_df)
    prob = model.predict_proba(input_scaled)[0][1]
    return int(prob >= 0.5), prob

# ------------------- BUTTON ACTION -------------------
if st.button('Predict Survival'):
    with st.spinner('Predicting...'):
        # Encode categorical values based on mappings
        features = [
            pclass,
            SEX_MAPPING[sex],
            age,
            sibsp,
            parch,
            fare,
            CABIN_MAPPING[cabin],
            EMBARKED_MAPPING[embarked]
        ]
        prediction, probability = predict_survival(features)

    st.write("---")
    if prediction:
        st.success(f"üéâ Likely to **SURVIVE**! Probability: {probability:.2%}")
    else:
        st.error(f"‚ùå Not likely to survive. Probability: {probability:.2%}")

