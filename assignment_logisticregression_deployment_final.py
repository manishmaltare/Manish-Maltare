# -*- coding: utf-8 -*-
"""ASSIGNMENT - LogisticRegression - Deployment - Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gmPcc_b1ChktZVuTt6Vm1lihRKaTwxpL
"""

import pandas as pd # LOAD DATASET
import joblib
features = pd.read_csv('Titanic_train.csv')
    
target = pd.read_csv('Titanic_test.csv')

# FEATURE EXTRACTION - i did perform it before EDA- 1 as the feature & target variable are given
# separately.

features.shape

target.shape

features.isnull().sum()

# DATA PREPROCESSING : - "Imputation"
# Imputation i am using here to fill the blank rows, keeping rows empty can lead to
# model not run.
# I am using imputation here by filling the 'age' column with mean value of overall rows.

features['Age']=features['Age'].fillna(features['Age'].mean())

features.isnull().sum()

# i am using imputation by applying most frequent rows into the blank ones in
# Embarked, as its having only 2-rows empty.

features['Embarked']=features['Embarked'].fillna(features['Embarked'].mode()[0])

features.isnull().sum()

# i am using imputation here, by first separating first letter of Cabin,
# beacause, it is deck no. which i feel is the only useful for process.
# After that i did put a random string 'U' in the null rows.

features['Cabin']=features['Cabin'].str[0]

features['Cabin']

features['Cabin']=features['Cabin'].fillna('U')

features['Cabin']

features.isnull().sum()

features.columns

features.nunique()

# I drop the columns PassengerID & Name.
# Main reason : - having data value in all rows unique, Regression will not work.
# PassengerID is just serial no. as per the registration. and in +1 incerasing order.
# Name - i believe would not matter, as there are string data, which is not eay to convert
# into continuous no. or binary

features=features.drop(['PassengerId','Name'],axis=1)

features=features.drop(['Ticket'],axis=1)

features.head()

# DATA PREPROCESSING : - "Encode categorical data"

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

features['Sex']=le.fit_transform(features['Sex'])

features.head()

features['Embarked']=le.fit_transform(features['Embarked'])

features.head()

features.nunique()

# removing ticket as its having 76% on unique values as string & integers.

features['Cabin']=le.fit_transform(features['Cabin'])

features.head()

target.head()

target.shape

target.nunique()

target.columns

target=target.drop(['PassengerId','Name'],axis=1)

target.head()

target.isnull().sum()

# Repeating the same steps of Data preprocessing for 'target' varable to prepare the dataset for prediction.

target['Age']=target['Age'].fillna(target['Age'].mean())

target.isnull().sum()

target['Cabin']=target['Cabin'].str[0]

target.head()

target['Cabin']=target['Cabin'].fillna('U')

target.head()

# merging 'features' & 'target' variables to perform EDA.
# EDA-1

data_merged=pd.concat([features,target],ignore_index=True)
data_merged.head()

data_merged.columns

data_merged.shape

data_merged.size

target['Sex']=le.fit_transform(target['Sex'])

target['Embarked']=le.fit_transform(target['Embarked'])

target['Cabin']=le.fit_transform(target['Cabin'])

target.head()

x = features.drop(['Survived'],axis=1)
x.head()

x.columns

y= features['Survived']
y.head()

# EDA-2 (MODEL BUILDING)
from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,train_size=0.8)

x_train.shape,x_test.shape,y_train.shape,y_test.shape

column_names=x_train.columns
column_names

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

x_train=sc.fit_transform(x_train)

x_test=sc.fit_transform(x_test)

from sklearn.linear_model import LogisticRegression

model=LogisticRegression()

model1 = model.fit(x_train,y_train)

scaler1 = sc.fit_transform(x_train)

# 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked'
scaler = pd.DataFrame(scaler1, columns=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked'])

joblib.dump(model,'logistic_reg_model.pkl') # Creating a PKL file for deployment later

joblib.dump(scaler,'scaler.pkl')

y_pred=model1.predict(x_train)

# MODEL EVALUATION
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_train,y_pred)
cm
# TP = 383 (correctly predicted survived)
# TN = 185 (correctly predicted not-survived)
# FP = 61 (incorrectly predicted survived)
# FN = 83 (incorrectly predicted not-survived)

from sklearn.metrics import classification_report

cr=classification_report(y_pred,y_train)

print(cr)

column_names

pd.DataFrame({'Column0': ['x1','x2','x3','x4','x5','x6','x7','x8'],'Column':column_names, 'Values': model.coef_.reshape(-1)})

# CHECKING TEST ACCURACY OF MODEL

model1=LogisticRegression()

model1=model1.fit(x_test,y_test)
model1

y_pred1=model1.predict(x_test)

y_pred1

cm1=confusion_matrix(y_pred1,y_test)
cm1
# TP = 92 (correctly predicted survived)
# TN = 58 (correctly predicted not-survived)
# FP = 16 (incorrectly predicted survived)
# FN = 13 (incorrectly predicted not-survived)

cr1=classification_report(y_pred1,y_test)

print(cr1) # Testing accuracy F1 - Score is 84%
# Testing model

target.head()

features.head()

target.isnull().sum()

target['Fare'].head()

target['Fare'].tail()

target['Fare'].iloc[152]

target.shape

target=target.drop([152])

target['Fare'].iloc[152]

target.shape

from sklearn.metrics import roc_curve, auc

# PREDICTION OF TARGET VARIABLES (using file "Titanic_test.csv" )
y_pred_new=model.predict(target)
y_pred_new

# Deployment :

model

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py


import streamlit as st
import pickle
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
import joblib
from sklearn.utils.validation import check_is_fitted

# Load the trained model and scaler
logistic_reg_model = LogisticRegression()
scaler = StandardScaler()
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(logistic_reg_model,'logistic_reg_model.pkl')


# Load the saved model and scaler
model = joblib.load('logistic_reg_model.pkl')
scaler = joblib.load('scaler.pkl')

# Load the trained model and scaler
try:
    with open('logistic_reg_model.pkl', 'rb') as file:
        model = pickle.load(file)
    with open('scaler.pkl', 'rb') as file:
        scaler = pickle.load(file)
    st.success("Model and scaler loaded successfully!")
except Exception as e:
    st.error(f"Error loading model or scaler: {e}")
    st.stop()

# Check if scaler is fitted (to catch the NotFittedError early)
try:
    check_is_fitted(scaler)
except Exception as e:
    st.error(f"Scaler is not fitted: {e}. Please re-train and save a fitted scaler.")
    st.stop()

# Title of the Streamlit app
st.title("Titanic Survival Prediction")

# Description
st.write("Enter passenger details to predict survival probability on the Titanic.")

# Input fields for features
pclass = st.selectbox("Passenger Class (Pclass)", [1, 2, 3])
sex = st.selectbox("Sex", ["male", "female"])
age = st.number_input("Age", min_value=0.0, max_value=100.0, value=30.0)
sibsp = st.number_input("Number of Siblings/Spouses Aboard (SibSp)", min_value=0, max_value=10, value=0)
parch = st.number_input("Number of Parents/Children Aboard (Parch)", min_value=0, max_value=10, value=0)
fare = st.number_input("Fare", min_value=0.0, max_value=600.0, value=30.0)
cabin = st.selectbox("Cabin Deck", ["A", "B", "C", "D", "E", "F", "G", "T", "U"])
embarked = st.selectbox("Port of Embarkation", ["C", "Q", "S"])

# Encode categorical variables
le_sex = LabelEncoder()
le_sex.fit(["male", "female"])
sex_encoded = le_sex.transform([sex])[0]

le_embarked = LabelEncoder()
le_embarked.fit(["C", "Q", "S"])
embarked_encoded = le_embarked.transform([embarked])[0]

le_cabin = LabelEncoder()
le_cabin.fit(["A", "B", "C", "D", "E", "F", "G", "T", "U"])
cabin_encoded = le_cabin.transform([cabin])[0]


# Create a DataFrame for the input
input_data = pd.DataFrame({
    'Pclass': [pclass],
    'Sex': [sex_encoded],
    'Age': [age],
    'SibSp': [sibsp],
    'Parch': [parch],
    'Fare': [fare],
    'Cabin': [cabin_encoded],
    'Embarked': [embarked_encoded]
})

# Scale the input data
input_scaled = scaler.fit_transform(input_data)
input_scaled1 = pd.DataFrame(input_scaled , columns=['Pclass','Sex','Age','SibSp','Parch','Fare','Cabin','Embarked'])

# Predict button
if st.button("Predict"):
    prediction = logistic_reg_model.pkl.predict(input_scaled1)
    probability = logistic_reg_model.pkl.predict_proba(input_scaled1)[0][1]  # Probability of survival

    # Display result
    if prediction[0] == 1:
        st.success(f"The passenger is likely to **survive** with a probability of {probability:.2f}.")
    else:
        st.error(f"The passenger is likely to **not survive** with a probability of {1 - probability:.2f}.")


