# -*- coding: utf-8 -*-
"""For Deployment Solar_Panel_Regression_Group_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L9ATSRfbOV1KdRwH0nC6o8o5Cj7Vs-pe
"""

import numpy as np
import pandas as pd
import pickle
from sklearn.ensemble import GradientBoostingRegressor

df = pd.read_csv('solarpowergeneration.csv')

df['average-wind-speed-(period)'] = df['average-wind-speed-(period)'].fillna(df['average-wind-speed-(period)'].mean())

df_features = df.drop(['power-generated'], axis=1)

scaled_df = df_features.copy()
for col in scaled_df.select_dtypes(include=[np.number]).columns:
    mean_val = scaled_df[col].mean()
    std_val = scaled_df[col].std()
    if std_val != 0:
        scaled_df[col] = (scaled_df[col] - mean_val) / std_val
    else:
        scaled_df[col] = 0.0

y = df['power-generated']
x = df_features

x_train = x.iloc[0:2336]

y_train = y.iloc[0:2336]

x_test = x.iloc[2336:2920]

y_test = y.iloc[2336:2920]

params = {
    'n_estimators': 100,
    'learning_rate': 0.1,
    'max_depth': 3,
    'random_state': 42
}

# Train the model
model = GradientBoostingRegressor(learning_rate= 0.1, max_depth= 3, n_estimators= 100, random_state= 42)
model.fit(x_train, y_train)
# Pickle the trained model (saves the model object with all parameters and trained state)
with open('gradient_boosting_model.pkl', 'wb') as f:
    pickle.dump(model, f)

import streamlit as st
import pandas as pd
import numpy as np
import pickle

# --------------------------------------------------------
# PAGE CONFIG
# --------------------------------------------------------
st.set_page_config(page_title="Solar Power Prediction App", layout="wide")

st.title("âš¡ Solar Power Generation Prediction App")

# --------------------------------------------------------
# LOAD MODEL & SCALER PARAMS
# --------------------------------------------------------
@st.cache_resource
def load_model():
    with open("gradient_boosting_model.pkl", "rb") as f:
        model = pickle.load(f)
    return model

@st.cache_resource
def load_scaler():
    with open("scaler_params.pkl", "rb") as f:
        params = pickle.load(f)
    return params

model = load_model()
scaler_params = load_scaler()

means = scaler_params["means"]
stds = scaler_params["stds"]

# --------------------------------------------------------
# USER INPUT SECTION
# --------------------------------------------------------
st.subheader("Enter Feature Inputs")

# Create input fields dynamically from feature list
def user_input_features():
    inputs = {}
    for feature in means.keys():
        inputs[feature] = st.number_input(
            f"{feature}", 
            value=float(means[feature]) if means[feature] is not None else 0.0
        )
    return pd.DataFrame([inputs])

# Get real-time user inputs
user_df = user_input_features()

st.write("### Raw Input Data")
st.dataframe(user_df)

# --------------------------------------------------------
# MANUAL SCALING (Standard Scaler Formula)
# --------------------------------------------------------
def manual_standard_scale(df):
    scaled = df.copy()
    for col in scaled.columns:
        mean_val = means[col]
        std_val = stds[col]
        if std_val != 0:
            scaled[col] = (scaled[col] - mean_val) / std_val
        else:
            scaled[col] = 0.0
    return scaled

scaled_user_df = manual_standard_scale(user_df)

st.write("### Scaled Data (Used for Prediction)")
st.dataframe(scaled_user_df)

# --------------------------------------------------------
# PREDICTION
# --------------------------------------------------------
if st.button("Predict Power Generation"):
    prediction = model.predict(scaled_user_df)[0]
    st.success(f"ðŸŒž **Predicted Power Generated:** {prediction:.2f} kW")

