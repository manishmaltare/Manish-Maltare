# -*- coding: utf-8 -*-
"""Pickle of ASSIGNMENT - LogisticRegression - Deployment - Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YSv7MZYOcWAHmiNHz4RF5JwWfbbNkNb6
"""

import pandas as pd # LOAD DATASET
import joblib
import pickle

new_df = pd.read_csv('Titanic_train.csv')
target = pd.read_csv('Titanic_test.csv')

new_df = pd.concat([new_df, target], ignore_index=True )

new_df['Sex'].value_counts()

new_df['SibSp'].value_counts()

new_df['Cabin'].value_counts()

new_df['Fare']=new_df['Fare'].fillna(new_df['Fare'].mean())

# FEATURE EXTRACTION - i did perform it before EDA- 1 as the feature & target variable are given
# separately.

# DATA PREPROCESSING : - "Imputation"
# Imputation i am using here to fill the blank rows, keeping rows empty can lead to
# model not run.
# I am using imputation here by filling the 'age' column with mean value of overall rows.
new_df['Age']=new_df['Age'].fillna(new_df['Age'].mean())

# i am using imputation by applying most frequent rows into the blank ones in
# Embarked, as its having only 2-rows empty.

new_df['Embarked']=new_df['Embarked'].fillna(new_df['Embarked'].mode()[0])

# i am using imputation here, by first separating first letter of Cabin,
# beacause, it is deck no. which i feel is the only useful for process.
# After that i did put a random string 'U' in the null rows.

new_df['Cabin']=new_df['Cabin'].str[0]

new_df['Cabin']=new_df['Cabin'].fillna('U')

# I drop the columns PassengerID & Name.
# Main reason : - having data value in all rows unique, Regression will not work.
# PassengerID is just serial no. as per the registration. and in +1 incerasing order.
# Name - i believe would not matter, as there are string data, which is not eay to convert
# into continuous no. or binary

new_df=new_df.drop(['PassengerId','Name'],axis=1)

# DATA PREPROCESSING : - "Encode categorical data"
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
emb_le=le.fit_transform(new_df['Embarked'])
sex_le=le.fit_transform(new_df['Sex'])
cabin_le=le.fit_transform(new_df['Cabin'])

new_df['Embarked']=emb_le
new_df['Sex']=sex_le
new_df['Cabin']=cabin_le

with open("emb_le.pkl", "wb") as file:
  pickle.dump(emb_le, file)

with open("cabin_le.pkl", "wb") as file:
  pickle.dump(cabin_le, file)

with open("sex_le.pkl", "wb") as file:
  pickle.dump(sex_le, file)

# removing ticket as its having 76% on unique values as string & integers.
new_df=new_df.drop(['Ticket'],axis=1)

x = new_df.drop(['Survived'],axis=1)
y= new_df['Survived']

y_train = y.iloc[0:891]

x_train = x.iloc[0:891]
x_test = x.iloc[892:1309]

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

x_train=sc.fit_transform(x_train)
scaler_model = sc.fit_transform(x_train)
with open("scaler_model.pkl", "wb") as file:
  pickle.dump(scaler_model, file)

x_test=sc.fit_transform(x_test)

from sklearn.linear_model import LogisticRegression
model=LogisticRegression()
model1 = model.fit(x_train,y_train)

with open("logistic_regression_model.pkl", "wb") as file:
  pickle.dump(model1, file)

import numpy as np
import pandas as pd

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py

import streamlit as st
import pickle
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression

# Load the trained model
with open("logistic_regression_model.pkl", "rb") as file:
    model = pickle.load(file)
with open("emb_le.pkl", "rb") as file1:
    emb_lee = pickle.load(file1)
with open("sex_le.pkl", "rb") as file2:
    sex_lee = pickle.load(file2)
with open("cabin_le.pkl", "rb") as file3:
    cabin_lee = pickle.load(file3)
with open("scaler_model.pkl", "rb") as file4:
    scaler_model = pickle.load(file4)

# Title of the Streamlit app
st.title("Titanic Survival Prediction")

# Description
st.write("Enter passenger details to predict survival probability on the Titanic.")

# Input fields for features
pclass = st.selectbox("Passenger Class (Pclass)", [1, 2, 3])
sex = st.selectbox("Sex", ["male", "female"])
age = st.number_input("Age", min_value=0, max_value=100, value=30)
sibsp = st.number_input("Number of Siblings/Spouses Aboard (SibSp)", min_value=0, max_value=10, value=0)
parch = st.number_input("Number of Parents/Children Aboard (Parch)", min_value=0, max_value=10, value=0)
fare = st.number_input("Fare", min_value=0, max_value=600, value=30)
cabin = st.selectbox("Cabin Deck", ["A", "B", "C", "D", "E", "F", "G", "T", "U"])
embarked = st.selectbox("Port of Embarkation", ["C", "Q", "S"])


# Create a DataFrame for the input
input_data = pd.DataFrame({
    'Pclass': [pclass],
    'Sex': [sex],
    'Age': [age],
    'SibSp': [sibsp],
    'Parch': [parch],
    'Fare': [fare],
    'Cabin': [cabin],
    'Embarked': [embarked]
})


    # 1. Label encode the categorical variables first
input_data['Sex'] = sex_lee.fit_transform(input_data['Sex'])
input_data['Cabin'] = cabin_lee.fit_transform(input_data['Cabin'])
input_data['Embarked'] = emb_lee.fit_transform(input_data['Embarked'])

    # 2. Separate numerical and categorical features for scaling
numerical_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex', 'Cabin', 'Embarked']
    
    # 3. Apply the pre-fitted StandardScaler to the numerical features
scaled_data = scaler_model.fit_transform(input_data[numerical_features])
    
    # 4. Create a new DataFrame with the scaled data
scaled_input_data = pd.DataFrame(scaled_data, columns=numerical_features)
    
    # 5. Make the prediction using the preprocessed data
prediction = model.predict(scaled_input_data)
probability = model.predict_proba(scaled_input_data)[0][1]  # Probability of survival

    # Display the result
if prediction[0] == 1:
    st.success(f"The passenger is likely to **survive** with a probability of {probability:.2f}.")
else:
    st.error(f"The passenger is likely to **not survive** with a probability of {1 - probability:.2f}.")
